# name: test/sql/copy/partitioned/hive_file_filter.test
# description: use ComplexFilterPushdown() to prune partitions and find files
# group: [partitioned]

require parquet

# enable_verification runs into optimization errors
# statement ok
# PRAGMA enable_verification

# create a table
statement ok
CREATE TABLE t(year INTEGER, month INTEGER, day INTEGER, val INTEGER);

foreach _year 1 2

foreach _month 1 2 3 4 5 6 7 8 9 10 11 12

foreach _day 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30

statement ok
INSERT INTO t VALUES(${_year},${_month},${_day},${_year}*${_month}*${_day});

endloop

endloop

endloop

query I
SELECT COUNT(*) FROM t;
----
720

# create hive partition
statement ok
COPY t TO '__TEST_DIR__/filter_partition' (FORMAT PARQUET, PARTITION_BY(year,month,day));

query I
SELECT COUNT(*) FROM GLOB('__TEST_DIR__/filter_partition/**');
----
720

# check amount of files (_year * 12 * 30)
query I
SELECT COUNT(*) FROM read_parquet('__TEST_DIR__/filter_partition/*/*/*/*.parquet', hive_partitioning=1, experimental_hive_filter=1);
----
720

query I
SELECT COUNT(*) FROM read_parquet('__TEST_DIR__/filter_partition/**', experimental_hive_filter=1);
----
720

query I
SELECT COUNT(*) FROM read_parquet('__TEST_DIR__/filter_partition/**', experimental_hive_filter=1) where year=1 and month>=1 and month<=12;
----
360

query I
SELECT COUNT(*) FROM read_parquet('__TEST_DIR__/filter_partition/**', experimental_hive_filter=1) where year=1 and month=10 and day=16;
----
1

query I
SELECT val FROM read_parquet('__TEST_DIR__/filter_partition/**', experimental_hive_filter=1) where year=1 and month=10 and day=16;
----
160

# check pattern matching
query I
SELECT COUNT(*) FROM read_parquet('__TEST_DIR__/filter_partition/year=*/month=*/day=*/*.parquet', experimental_hive_filter=1);
----
720

query I
SELECT COUNT(*) FROM read_parquet('__TEST_DIR__/filter_partition/**/*.parquet', experimental_hive_filter=1);
----
720

query I
SELECT COUNT(*) FROM read_parquet('__TEST_DIR__/filter_partition/*/mon?h=1?/day=?/*.parquet', experimental_hive_filter=1);
----
54

# Test some wonky partitioning schemes
query IIII
select id, value, part, date from parquet_scan('data/parquet-testing/hive-partitioning/different_order/*/*/test.parquet', HIVE_PARTITIONING=1, experimental_hive_filter=1) where date='2012-01-01'
----
1	value1	a	2012-01-01

query IIII
select id, value, part, date from parquet_scan('data/parquet-testing/hive-partitioning/different_order/*/*/test.parquet', HIVE_PARTITIONING=1, experimental_hive_filter=1) where date='2013-01-01'
----
2	value2	b	2013-01-01

# FIXME: Note that the filter currently has weird behaviour on broken schemes, this query should fail but it doesn't
statement ok
select * from parquet_scan('data/parquet-testing/hive-partitioning/mismatching_names/*/*/test.parquet', HIVE_PARTITIONING=1, experimental_hive_filter=1)

# TODO: Add more tests for better error handling in corrupt datasets / parquet files.